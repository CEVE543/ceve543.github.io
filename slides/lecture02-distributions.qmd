---
title: "Introduction to statistics and probability distributions"
subtitle: "Lecture"
date: "August 28, 2023"

# don't adjust the below options, they should be the same for all slides
author: "{{< var instructor.name >}}!"
course: "{{< var course.number >}}, {{< var course.title >}}"
institution: "{{< var course.institution >}}}"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        footer: "[{{< var course.number >}}, {{< var course.title >}}]({{< var course.url >}})"
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: mathjax
        include-in-header: mathjax-config.html
        date-format: long
        code-annotations: below

execute:
    freeze: auto
    echo: true
---

## A quick note on pacing

We will move through this module ("fundamentals") at a fairly brisk [pace](../schedule.qmd)

- Review course slides
- Ask questions on Canvas or in office hours
- To help you learn to code, I am exposing you to code early and often
    - I don't expect that you are able to replicate all the code in this notebook
    - I have added annotations where appropriate
    - The labs will give you practice
    - You will not need to write code from scratch for the exams

::: {.notes}
This is a long slide deck. We will probably finish on Wednesday
:::

# Packages in Julia

## What is a package?

- Code that is bundled for easy use
- Provides functionality that is not part of the base language  
    - Most stuff in Julia requires packages, as we will see
- Need to be installed
- Developed by the community

## Where do I get packages?

> Julia has a built-in package manager for installing add-on functionality written in Julia. It can also install external libraries using your operating system's standard system for doing so, or by compiling from source.

## Where are packages stored?

Each *project* has an *environment, which is defined by the following files (do not edit them manually):

- `Project.toml`: lists the *specified dependencies* of the project
- `Manifest.toml`: lists the *exact versions* of the packages that are used in the project

The actual packages are stored on your computer and you don't need to worry

## Workflow: activate

We `activate` a project to tell Julia that we want to use the packages in that project.
These steps are equivalent:

:::: {.columns}
::: {.column width="50%"}

 1. Open the REPL
 2. `using Pkg`
 3. `Pkg.activate(".")`

:::
::: {.column width="50%"}

 1. Open the REPL
 2. Press `]` to enter the package manager
 3. `activate .`

:::
::::

## Workflow: install

We `add` a package to install it in the current project

:::: {.columns}
::: {.column width="50%"}

 1. Open the REPL
 2. `using Pkg`
 3. `Pkg.add("DataFrames")`

:::
::: {.column width="50%"}

 1. Open the REPL
 2. Press `]` to enter the package manager
 3. `add DataFrames`

:::
::::

## Workflow: instantiate

When working with someone else's project, we need to install the packages that they use.

- `activate` does not install anything, just tells Julia which packages to use
- `instantiate` is your friend to make sure an environment is ready to use. If there's nothing to do, instantiate does nothing.

## Learn more

1. [`Pkg.jl` docs](https://pkgdocs.julialang.org/v1/getting-started/)
    1. See ["Using someone else's projecg"](https://pkgdocs.julialang.org/v1/environments/#Using-someone-else%27s-project) for more on `instantiate`
1. [Well-worked blog post](https://jkrumbiegel.com/pages/2022-08-26-pkg-introduction/index.html) by [Julies Krumbiegel](https://jkrumbiegel.com/)

## Lab 01 issues

::: {.incremental}
- Be sure to submit your assignment
- Canvas discussion: "Lab 01 Discussion"
- `ERROR: Jupyter kernel 'julia-1.9' not found.` x4
:::

## Lab 01 fix

- In order to run codes using Quarto, you need the `IJulia` package    
    - Listed in `Manifest.toml` but you need to `instantiate`
- If that doesn't work:
    - Run `Pkg.build("IJulia")` in the REPL (after you `activate` and `instantiate`)
- I've updated the [instructions](../labs/lab01/instructions.qmd)

# Effect of beer drinking on attractiveness to mosquitos

## Stats without the agonizing details

In this class we will use computation and simulation to build fundamental insight into statistical processes without dwelling on "agonizing" details.

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/5Dnw46eC-0o?si=3Y3JKwkwD9i6lrVV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Motivating question

> Does drinking beer reduce the likelihood of being bitten by mosquitos?

## Raw data

Create a *variable* called `beer` to hold the number of mosquito bites for beer drinkers:

```{julia}
beer = [27, 20, 21, 26, 27, 31, 24, 21, 20, 19, 23, 24, 28, 19, 24, 29, 18, 20, 17, 31, 20, 25, 28, 21, 27]
```

## What is `beer`?

We can learn a bit more about it:

```{julia}
typeof(beer)
```

```{julia}
length(beer)
```

```{julia}
size(beer)
```

```{julia}
sum(beer) / length(beer) # the sample average
```

## More raw data

We can do the same for water drinkers:

```{julia}
water = [21, 22, 15, 12, 21, 16, 19, 15, 22, 24, 19, 23, 13, 22, 20, 24, 18, 20]; # <1>
```
1. By putting the `;` at the end of our statement, we keep the notebook from showing the output

## A simple analysis

Let's calculate the difference between the average number of bites in each group.

```{julia}
using StatsBase: mean # <1>

observed_diff = mean(beer) - mean(water)
observed_diff
```
1. This gives us the `mean` function from the `StatsBase` package

## The skeptic's argument {.scrollable}

The skeptic asks whether this might be random chance.

::: {.incremental}
1. We could answer this with a T test
    1. Determine if there is a significant difference between the means of two groups
    1. Assumes (approximate) normality
    1. Assumptions hidden behind a software package
1. Simulation approach:
    1. Suppose the skeptic is right -- the two groups are samped from the same distribution
    1. Shuffle the data (randomly divide into two groups by assuming that there is no difference between the two groups)
    1. Calculate the difference between each group
    1. Repeat many times and examine the distribution of differences
:::

::: {.notes}
Make clear that we want to relax our assumptions and to simplify the analysis.
Some of the things T tests make you think about, like whether data is paired or not, whether the variances are equal, whether you want one or two direction, etc are important and figure into the design of your simulation approach.
:::

## Implementation {.smaller}

```{julia}
using Random: shuffle # <1>

function get_shuffled_difference(y1, y2) # <2>

    # concatenate the data into one vector, then shuffle it
    y_all = vcat(y1, y2)
    y_shuffled = shuffle(y_all)

    # create groups consistent w/ skeptic's argument
    N1 = length(y1) # how many obs in the first vector?
    ynew1 = y_shuffled[1:N1]
    ynew2 = y_shuffled[(N1+1):end]

    # get the difference
    difference = mean(ynew1) - mean(ynew2)
    return difference
end # <3>

get_shuffled_difference(beer, water) # <4>
```
1. Use the `shuffle` function from the `Random` package
2. Define a function. Its arguments are `y1` and `y2`
3. `end` closes the function definition
4. Call the function with our data

## Running

We want to learn about the *sampling distribution* of the group differences: repeat this experiment many times over and plott the results

```{julia}
simulated_diffs = [get_shuffled_difference(beer, water) for i in 1:50_000] # <1>
length(simulated_diffs) # <2>
```

1. This is a *list comprehension*. It's a way to create a list by looping over something. Here, we loop over the numbers 1 to 50,000 and call `get_shuffled_difference` each time.
2. `length` tells us the size of a vector

## Plotting {.scrollable}

```{julia}
using Plots # <1>

function plot_diffs(diffs, obs) # <2>
    p = histogram( # <3>
        diffs; # <4>
        xlabel="Difference", # <5>
        ylabel="Proportion of samples", # <6>
        label="If Skeptic is Right", # <7>
        bins=-6:0.5:6, # <8>
        legend=:topleft, # <9>
        normalize=true, # <10>
    )
    vline!(p, [obs]; label="Observed", linewidth=2) # <11>
    return p # <12>
end
plot_diffs(simulated_diffs, observed_diff)
```

1. We need the `Plots` package to make plots
2. Define a function. Its arguments are `diffs` and `obs`
3. `histogram` is a function from the `Plots` package
4. Create a histogram using the `diffs` object. `;` separates the positional arguments from the keyword arguments
5. `xlabel` is a "keyword argument" specifying the text for the x-axis label
6. the y-axis label
7. the label to use in the legend
8. specify the bins to use in the histogram
9. specify the location of the legend
10. normalize the histogram so that the area under the curve is 1
11. add a vertical line (`vline!`) at the observed difference
12. many functions *return* their output -- in this case the plot we created from the inputs

## Alternative

We could have done this with a parametric test

```{julia}
using HypothesisTests # <1>

t1 = HypothesisTests.EqualVarianceTTest(beer, water) # <2>
t2 = HypothesisTests.UnequalVarianceTTest(beer, water); # <3>
```

1. We need the `HypothesisTests` package
2. We don't need to include the `HypothesisTests.`, but it adds clarity
3. Recall: `;` suppresses output

:::: {.columns}
::: {.column width="50%"}

```{julia}
t1
```

:::
::: {.column width="50%"}

```{julia}
t2
```

:::
::::

## Discussion

::: {.incremental}

- This is called a *bootstrap* and is a very powerful tool in many situations
- What would we expect to see if the skeptic was correct?
- P-value:
    - the *likelihood* of the data if the *null hypothesis* is correct
    - skeptic's (null) hypothesis: no difference between groups
:::

. . .

```{julia}
mean(simulated_diffs .>= observed_diff) # <1>
```
1. `.` is the *dot operator*. It applies the function to each element of the vector individually.

# Probability distributions

## The Normal distribution

The Normal (Gaussian) distribution has *probability distribution function*:

$$
p(y | \mu, \theta) = \frac{1}{\sigma\sqrt{2\pi}} \exp
\left(
-\frac{1}{2}\left(
\frac{x-\mu}{\sigma}
\right)^{\!2}
\,
\right)
$$

- Mean $\mu$
    - Median equal to mean
- Variance $\sigma^2$
- Symmetric

## Central limit theorem {.scrollable}

The *central limit theorem* says that the sum of many independent random variables is approximately normally distributed.

We can see this with an example:

1. For each sample $i = 1, \ldots, N$:
    1. Draw `J` draws from a non-Gaussian distribution $\mathcal{D}$
    2. Take the mean and save it as $\bar{y}_i$
2. Plot the distribution of $\bar{y}_i$

```{julia}
using Distributions

dist = Gamma(2, 1) # a non-Gaussian distribution
N = 10_000 # number of samples
J = 500 # draws per sample
ȳ = [ # <1>
    mean(rand(dist, J))
    for _ ∈ 1:N # <2>
] # <3>
histogram(
    ȳ;
    xlabel="Sample mean",
    ylabel="Proportion of samples",
    normalize=true,
    label=false,
)
```
1. To type `ȳ`, type `y` then type `\bar` and hit `tab`. Julia allows unicode (or emojis) in variable names
2. To type `∈` , type `\in` and hit `tab`. The `_` isn't doing anything special and we could name it `i` or 😶 or whatever we want but `_` suggests it's a throwaway
3. This is another *list comprehension*

## Notation

We will get tired of writing

$$
p(y | \mu, \theta) = \frac{1}{\sigma\sqrt{2\pi}} \exp
\left(
-\frac{1}{2}\left(
\frac{x-\mu}{\sigma}
\right)^{\!2}
\,
\right)
$$

Instead, we will often use shorthand:

$$
y \sim \mathcal{N}(\mu, \sigma^2)
$$

## Normal PDF {.scrollable}

```{julia}
using StatsPlots
using LaTeXStrings
using Distributions

plot(
    Normal(0, 1);
    label="Normal Distribution",
    xlabel=L"$x$", # <1>
    ylabel=L"$p(x | \mu=0, \sigma=1)$", # <2>
)
```
1. `L"<string>"` allows us to use LaTeX in strings
2. This notation specifies the values of $\mu$ and $\sigma$

## Bernoulli distribution

A Bernoulli distribution models a coin flip.

```{julia}
p = 0.5 # probability of heads
rand(Bernoulli(p), 5) # <1>
```
1. Draw 5 samples from the Bernoulli distribution with parameter `p`

## Binomial distribution

A Binomial distribution models the distribution of `n` consecutive flips of the same coin

```{julia}
p = 0.5
N = 5
rand(Binomial(N, p), 5)
```

## Multinomial distribution

The Multinomial extends the Binomial to multiple categories.
Note that `p` is a *vector*.
If there are 2 categories ($K=2$), it's just the binomial with $p_\text{multinomial} = [p, 1-p]$."

```{julia}
p = [0.5, 0.3, 0.2]
N = 5
dist = Multinomial(N, p)
rand(dist, 5) # <1>
```
1. To be more concise, we could write `rand(Multinimial([0.5, 0.3, 0.2], 5), 5)`. Which is more readable?

## Poisson distribution {.scrollable}

The Poisson distribution is used to model count data.
It is the limit of a Binomial distribution with $p=\lambda/N$, as $N \rightarrow \infty$.

A Poisson distribution has mean and variance equal to $\lambda$.

```{julia}
dist = Poisson(2.5) # <1>
rand(dist, 10) # <2>
```

1. The Poisson distribution has one parameter, $\lambda$
2. Draw 10 samples from the Poisson distribution

## Negative binomial distribution

The `NegativeBinomaial` distribution relaxes the Poisson's assumotion that $\text{mean} = \text{variance}$.

This distribution models the number of successes in a sequence of independent and identically distributed Bernoulli trials with probability `p` before a specified (non-random) number of failures (`r`) occurs.
For example, we can define rolling a 6 on a dice as a failure, and rolling any other number as a success, and ask how many successful rolls will occur before we see the third failure (`p = 1/6` and `r = 3`).

## What other distributions do you know?

. . .

- Uniform
- Exponential
- Gamma (see above)
- Beta
- Pareto
- Student t
- Boltzmann
- Many more!

# Statistics

## Mean

The mean of a sample is just the sample average:
$$
\bar{y} = \frac{1}{N} \sum_{i=1}^N y_i
$$

. . .

The mean of a distribution is the expected value of the distribution:
$$
\mathbb{E}(u) = \int u p(u) \, du
$$

## Variance {.smaller}

Variance measures how points differ from the mean

. . .

You may be familiar with sample variance:
$$
S^2 = \frac{\sum_{i=1}^n (x_i - \bar{x})^2}{n - 1}
$$

. . .

For a distribution:
$$
\mathbb{V}(u) = \int (u - \mathbb{E}(u))^2 p(u) \, du
$$
or, for a vector
$$
\mathbb{V}(u) = \int (u - \mathbb{E}(u)) (u - \mathbb{E}(u))^T p(u) \, du
$$

# Wrapup

## Coming up

- Wednesday: working with probability distributions
- Friday:    
    - Lab 02: Working with tabular data in Julia
    - Lab 01 due *at start of class*

## Office hours

If you haven't filled out the Doodle, please do so ASAP
